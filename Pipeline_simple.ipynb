{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Exploration\n",
    "the goal of this notebook is to explore the data that we are working with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import plotly.express as px\n",
    "from unidecode import unidecode\n",
    "import json"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# Concatenating Traning Files"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def merge_training_files(training_folder, training_agr_path, verbose = False):\n",
    "    # importing the csv files\n",
    "    # The path for listing items\n",
    "    path = training_folder\n",
    "\n",
    "    # All files in the source folder\n",
    "    files = os.listdir(path)\n",
    "\n",
    "    # Filter out non training data\n",
    "    r = re.compile(\"train-*\")\n",
    "    files = list(filter(r.match, files))\n",
    "\n",
    "    # Aggregate training files\n",
    "    valid_columns = [\"tconst\", \"primaryTitle\", \"originalTitle\", \"startYear\", \"endYear\", \"runtimeMinutes\", \"numVotes\", \"label\"]\n",
    "    data = pd.DataFrame(columns=valid_columns)\n",
    "    size_counter = 0\n",
    "    for filename in files:\n",
    "        filepath = path+filename\n",
    "        _data = pd.read_csv(path+filename, index_col=0)\n",
    "        data = pd.concat([data, _data], ignore_index=True)\n",
    "\n",
    "        size_counter += _data.shape[0]\n",
    "        if verbose: print(f'file: {filename} - {_data.shape[0]} | total {size_counter}')\n",
    "    if verbose: print(f' >> data shape: {data.shape}')\n",
    "\n",
    "    data.to_csv(training_agr_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# training_folder = './source_imdb/'\n",
    "# data = merge_training_files(training_folder)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating directors and writers files"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def construct_writers_directors(writer_path, director_path, output_path):\n",
    "    with open(writer_path, 'r') as w:\n",
    "        _ = json.load(w)\n",
    "        writers = {}\n",
    "        for dict in _:\n",
    "            writers[dict[\"movie\"]] = dict[\"writer\"]\n",
    "\n",
    "    with open(director_path, 'r') as d:\n",
    "        _ = json.load(d)\n",
    "        directors = {}\n",
    "        for key, movie in _['movie'].items():\n",
    "            directors[movie] = _[\"director\"][key]\n",
    "\n",
    "    # print(f'writer count: {len(writers)}, director count: {len(directors)}')\n",
    "\n",
    "    d = {k: {'writer': w, 'director': directors[k]} for k,w in writers.items()}\n",
    "\n",
    "    del _, writers, directors\n",
    "\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(d, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# writer_path   = 'source_imdb/writing.json'\n",
    "# director_path = 'source_imdb/directing.json'\n",
    "# writer_director_path   = 'output/writers_directors.json'\n",
    "#\n",
    "# construct_writers_directors(writer_path, director_path, writer_director_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Matching writers and directors to movies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def writer_director_lookup(tconst, writer_director_dict):\n",
    "    '''matches given tconst to writer and directs, pergorms a similarity check'''\n",
    "    writer = writer_director_dict[tconst]['writer']\n",
    "    director = writer_director_dict[tconst]['director']\n",
    "    same = (writer == director)\n",
    "    return writer, director, same\n",
    "\n",
    "def match_writer_director(dataframe, writer_director_path):\n",
    "    with open(writer_director_path, 'r') as w_d_json:\n",
    "        w_d_dict = json.load(w_d_json)\n",
    "        dataframe['writer'], dataframe['director'], dataframe['same_writer_director'] = \\\n",
    "            zip(*[writer_director_lookup(t, w_d_dict) for t in dataframe['tconst']])\n",
    "    return dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# data = match_writer_director(data, writer_director_path)\n",
    "# data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# fixing d-types"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def fix_dtypes(dataframe):\n",
    "    integer_columns  = [\"startYear\", \"endYear\", \"runtimeMinutes\", \"numVotes\"]\n",
    "    bool_columns  = [\"label\", \"same_writer_director\"]\n",
    "    string_columns  = [\"tconst\", \"primaryTitle\", \"originalTitle\", \"writer\", \"director\"]\n",
    "\n",
    "    for c in integer_columns:\n",
    "        dataframe[c] = pd.to_numeric(dataframe[c], errors=\"coerce\")\n",
    "    for c in string_columns:\n",
    "        dataframe[c] = dataframe[c].astype('string')\n",
    "    for c in bool_columns:\n",
    "        if c in dataframe.columns:\n",
    "            dataframe[c] = dataframe[c].astype('boolean')\n",
    "\n",
    "    # print(dataframe.dtypes)\n",
    "\n",
    "    return dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cleaning text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "# fix lexical bullshit from title column\n",
    "def clean_text(text: str):\n",
    "    text = re.sub(r'[^\\w\\s]','',text)\n",
    "    text = text.lower()\n",
    "    text = unidecode(text)\n",
    "    return text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# Brining the processing together"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def clean_data(raw_data_path):\n",
    "    \"\"\"Join all the data preprocessing steps here\"\"\"\n",
    "    dataframe = pd.read_csv(raw_data_path, index_col=0)\n",
    "    dataframe = match_writer_director(dataframe, writer_director_path)\n",
    "    dataframe = fix_dtypes(dataframe)\n",
    "    return dataframe\n",
    "\n",
    "def feature_engineer_data(dataframe):\n",
    "    \"\"\"All feature engineering steps go here\"\"\"\n",
    "    return dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "# prexisting data\n",
    "training_folder         = './source_imdb/'\n",
    "validation_path         = 'source_imdb/validation_hidden.csv'\n",
    "test_path               = 'source_imdb/test_hidden.csv'\n",
    "writer_path             = 'source_imdb/writing.json'\n",
    "director_path           = 'source_imdb/directing.json'\n",
    "\n",
    "# our data\n",
    "training_agr_path       = 'output/train_aggregated.csv'\n",
    "writer_director_path    = 'output/writers_directors.json'\n",
    "\n",
    "# construct information stores\n",
    "merge_training_files(training_folder, training_agr_path, verbose = False)\n",
    "construct_writers_directors(writer_path, director_path, writer_director_path)\n",
    "\n",
    "# clean the three sets\n",
    "train_clean = clean_data(training_agr_path)\n",
    "valid_clean  = clean_data(validation_path)\n",
    "test_clean  = clean_data(test_path)\n",
    "\n",
    "# apply feature engineering steps\n",
    "train_df = feature_engineer_data(train_clean)\n",
    "valid_df  = feature_engineer_data(valid_clean)\n",
    "test_df  = feature_engineer_data(test_clean)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# Model training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "import h2o\n",
    "from h2o.estimators import H2OXGBoostEstimator\n",
    "from h2o.grid.grid_search import H2OGridSearch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 . connected.\n"
     ]
    },
    {
     "data": {
      "text/plain": "--------------------------  -----------------------------\nH2O_cluster_uptime:         1 hour 9 mins\nH2O_cluster_timezone:       Europe/Amsterdam\nH2O_data_parsing_timezone:  UTC\nH2O_cluster_version:        3.36.0.3\nH2O_cluster_version_age:    1 month and 6 days\nH2O_cluster_name:           H2O_from_python_e_pg7917\nH2O_cluster_total_nodes:    1\nH2O_cluster_free_memory:    8.87 Gb\nH2O_cluster_total_cores:    8\nH2O_cluster_allowed_cores:  8\nH2O_cluster_status:         locked, healthy\nH2O_connection_url:         http://localhost:54321\nH2O_connection_proxy:       {\"http\": null, \"https\": null}\nH2O_internal_security:      False\nPython_version:             3.9.7 final\n--------------------------  -----------------------------",
      "text/html": "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n<td>1 hour 9 mins</td></tr>\n<tr><td>H2O_cluster_timezone:</td>\n<td>Europe/Amsterdam</td></tr>\n<tr><td>H2O_data_parsing_timezone:</td>\n<td>UTC</td></tr>\n<tr><td>H2O_cluster_version:</td>\n<td>3.36.0.3</td></tr>\n<tr><td>H2O_cluster_version_age:</td>\n<td>1 month and 6 days </td></tr>\n<tr><td>H2O_cluster_name:</td>\n<td>H2O_from_python_e_pg7917</td></tr>\n<tr><td>H2O_cluster_total_nodes:</td>\n<td>1</td></tr>\n<tr><td>H2O_cluster_free_memory:</td>\n<td>8.87 Gb</td></tr>\n<tr><td>H2O_cluster_total_cores:</td>\n<td>8</td></tr>\n<tr><td>H2O_cluster_allowed_cores:</td>\n<td>8</td></tr>\n<tr><td>H2O_cluster_status:</td>\n<td>locked, healthy</td></tr>\n<tr><td>H2O_connection_url:</td>\n<td>http://localhost:54321</td></tr>\n<tr><td>H2O_connection_proxy:</td>\n<td>{\"http\": null, \"https\": null}</td></tr>\n<tr><td>H2O_internal_security:</td>\n<td>False</td></tr>\n<tr><td>Python_version:</td>\n<td>3.9.7 final</td></tr></table></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init(max_mem_size_GB=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "y: label\n",
      "X: ['tconst', 'primaryTitle', 'originalTitle', 'startYear', 'endYear', 'runtimeMinutes', 'numVotes', 'writer', 'director', 'same_writer_director']\n"
     ]
    }
   ],
   "source": [
    "# Set the predictors and response; set the response as a factor:\n",
    "train_hf = h2o.H2OFrame(train_df)\n",
    "\n",
    "y = \"label\"\n",
    "X = train_hf.columns\n",
    "X = list(filter(lambda x: x not in [y], X))\n",
    "print(f'y: {y}')\n",
    "print(f'X: {X}')\n",
    "\n",
    "# Split the dataset into a train and valid set:\n",
    "train, valid = train_hf.split_frame(ratios=[.8], seed=1234)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost Grid Build progress: |█ (cancelled)\n",
      "Errors/Warnings building gridsearch model\n",
      "\n",
      "Hyper-parameter: col_sample_rate, 0.5\n",
      "Hyper-parameter: learn_rate, 0.3\n",
      "Hyper-parameter: max_depth, 3\n",
      "Hyper-parameter: ntrees, 50\n",
      "Hyper-parameter: sample_rate, 0.8\n",
      "Hyper-parameter: skip_drop, 0.0\n",
      "failure_details: Job Canceled\n",
      "failure_stack_traces: java.lang.RuntimeException: Error while training XGBoost model\n",
      "\tat hex.tree.xgboost.XGBoost$XGBoostDriver.buildModelImpl(XGBoost.java:443)\n",
      "\tat hex.tree.xgboost.XGBoost$XGBoostDriver.buildModel(XGBoost.java:395)\n",
      "\tat hex.tree.xgboost.XGBoost$XGBoostDriver.computeImpl(XGBoost.java:381)\n",
      "\tat hex.ModelBuilder$Driver.compute2(ModelBuilder.java:247)\n",
      "\tat water.H2O$H2OCountedCompleter.compute(H2O.java:1658)\n",
      "\tat jsr166y.CountedCompleter.exec(CountedCompleter.java:468)\n",
      "\tat jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)\n",
      "\tat jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:976)\n",
      "\tat jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1479)\n",
      "\tat jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)\n",
      "Caused by: water.Job$JobCancelledException\n",
      "\tat hex.tree.xgboost.XGBoost$XGBoostDriver.scoreAndBuildTrees(XGBoost.java:503)\n",
      "\tat hex.tree.xgboost.XGBoost$XGBoostDriver.buildModelImpl(XGBoost.java:441)\n",
      "\t... 9 more\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "H2OJobCancelled",
     "evalue": "Job<$03017f00000132d4ffffffff$_9f5a01bd9f5b7032af24a62992a14202> was cancelled by the user.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mH2OJobCancelled\u001B[0m                           Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/sx/rf0mky_55k347433qghmqlmm0000gn/T/ipykernel_2934/2613442377.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     12\u001B[0m                                 \u001B[0mgrid_id\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'xgb_grid_ntrees'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m                                 hyper_params=xgb_params)\n\u001B[0;32m---> 14\u001B[0;31m xgb_grid.train(\n\u001B[0m\u001B[1;32m     15\u001B[0m     \u001B[0mx\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m     \u001B[0mtraining_frame\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/h2o/grid/grid_search.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(self, x, y, training_frame, offset_column, fold_column, weights_column, validation_frame, **params)\u001B[0m\n\u001B[1;32m    349\u001B[0m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mxset\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    350\u001B[0m         \u001B[0mparms\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"x\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 351\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbuild_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparms\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    352\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    353\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/h2o/grid/grid_search.py\u001B[0m in \u001B[0;36mbuild_model\u001B[0;34m(self, algo_params)\u001B[0m\n\u001B[1;32m    386\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    387\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_estimator_type\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"unsupervised\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 388\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_model_build\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtraining_frame\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalidation_frame\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0malgo_params\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    389\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    390\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_model_build\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtframe\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvframe\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/h2o/grid/grid_search.py\u001B[0m in \u001B[0;36m_model_build\u001B[0;34m(self, x, y, tframe, vframe, kwargs)\u001B[0m\n\u001B[1;32m    404\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgrid_id\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"grid_id\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgrid_id\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    405\u001B[0m         \u001B[0mrest_ver\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"_rest_version\"\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0;34m\"_rest_version\"\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mkwargs\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 406\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_run_grid_job\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrest_ver\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mrest_ver\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    407\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    408\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_run_grid_job\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mparams\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mend_point\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrest_ver\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/h2o/grid/grid_search.py\u001B[0m in \u001B[0;36m_run_grid_job\u001B[0;34m(self, params, end_point, rest_ver)\u001B[0m\n\u001B[1;32m    413\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    414\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 415\u001B[0;31m                 \u001B[0mgrid\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpoll\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    416\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_handle_build_finish\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgrid\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrest_ver\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    417\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mH2OJobCancelled\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/h2o/job.py\u001B[0m in \u001B[0;36mpoll\u001B[0;34m(self, poll_updates)\u001B[0m\n\u001B[1;32m     85\u001B[0m         \u001B[0;31m# check if failed... and politely print relevant message\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     86\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstatus\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"CANCELLED\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 87\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mH2OJobCancelled\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Job<%s> was cancelled by the user.\"\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjob_key\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     88\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstatus\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"FAILED\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     89\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjob\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdict\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;34m\"stacktrace\"\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjob\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mH2OJobCancelled\u001B[0m: Job<$03017f00000132d4ffffffff$_9f5a01bd9f5b7032af24a62992a14202> was cancelled by the user."
     ]
    }
   ],
   "source": [
    "xgb_params = {\n",
    "        # 'learn_rate': [0.01, 0.1],\n",
    "        'max_depth': [3, 5, 9],\n",
    "        'sample_rate': [0.8, 1.0],\n",
    "        'col_sample_rate': [0.2, 0.5, 1.0],\n",
    "        # 'skip_drop': [0, 0.5, 1.0],\n",
    "        'ntrees': [30, 50, 100, 200, 300],\n",
    "}\n",
    "\n",
    "# Train and validate a cartesian grid of GBMs\n",
    "xgb_grid = H2OGridSearch(model=H2OXGBoostEstimator,\n",
    "                                grid_id='xgb_grid_ntrees',\n",
    "                                hyper_params=xgb_params)\n",
    "xgb_grid.train(\n",
    "    x=X, y=y,\n",
    "    training_frame=train,\n",
    "    validation_frame=valid,\n",
    "    seed=35\n",
    ")\n",
    "\n",
    "# Get the grid results, sorted by validation RMSE\n",
    "xgb_grid_ntrees_perf = xgb_grid.get_grid(sort_by='RMSE', decreasing=False)\n",
    "xgb_grid_ntrees_perf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost Model Build progress: |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/e/opt/anaconda3/lib/python3.9/site-packages/h2o/estimators/estimator_base.py:208: RuntimeWarning: Dropping bad and constant columns: [primaryTitle, tconst]\n",
      "  warnings.warn(mesg[\"message\"], RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "██████████████████████████████████████████████████| (done) 100%\n",
      "Model Details\n",
      "=============\n",
      "H2OXGBoostEstimator :  XGBoost\n",
      "Model Key:  XGBoost_model_python_1647970082100_4183\n",
      "\n",
      "\n",
      "Model Summary: \n"
     ]
    },
    {
     "data": {
      "text/plain": "     number_of_trees\n0              200.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>number_of_trees</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>200.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: xgboost\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.0871641245075922\n",
      "RMSE: 0.29523571008194827\n",
      "LogLoss: 0.29623792719762754\n",
      "Mean Per-Class Error: 0.10271989103857493\n",
      "AUC: 0.9631350157612215\n",
      "AUCPR: 0.968267514213273\n",
      "Gini: 0.926270031522443\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.44603567251137327: \n"
     ]
    },
    {
     "data": {
      "text/plain": "           False    True   Error             Rate\n0  False  2873.0   295.0  0.0931   (295.0/3168.0)\n1   True   361.0  2853.0  0.1123   (361.0/3214.0)\n2  Total  3234.0  3148.0  0.1028   (656.0/6382.0)",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>False</th>\n      <th>True</th>\n      <th>Error</th>\n      <th>Rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>2873.0</td>\n      <td>295.0</td>\n      <td>0.0931</td>\n      <td>(295.0/3168.0)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>True</td>\n      <td>361.0</td>\n      <td>2853.0</td>\n      <td>0.1123</td>\n      <td>(361.0/3214.0)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Total</td>\n      <td>3234.0</td>\n      <td>3148.0</td>\n      <td>0.1028</td>\n      <td>(656.0/6382.0)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/plain": "                         metric  threshold        value    idx\n0                        max f1   0.446036     0.896888  208.0\n1                        max f2   0.285174     0.919860  269.0\n2                  max f0point5   0.577778     0.925011  164.0\n3                  max accuracy   0.446036     0.897211  208.0\n4                 max precision   0.999483     1.000000    0.0\n5                    max recall   0.038624     1.000000  388.0\n6               max specificity   0.999483     1.000000    0.0\n7              max absolute_mcc   0.487176     0.796188  193.0\n8    max min_per_class_accuracy   0.433802     0.895202  212.0\n9   max mean_per_class_accuracy   0.446036     0.897280  208.0\n10                      max tns   0.999483  3168.000000    0.0\n11                      max fns   0.999483  3095.000000    0.0\n12                      max fps   0.005149  3168.000000  399.0\n13                      max tps   0.038624  3214.000000  388.0\n14                      max tnr   0.999483     1.000000    0.0\n15                      max fnr   0.999483     0.962974    0.0\n16                      max fpr   0.005149     1.000000  399.0\n17                      max tpr   0.038624     1.000000  388.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>metric</th>\n      <th>threshold</th>\n      <th>value</th>\n      <th>idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>max f1</td>\n      <td>0.446036</td>\n      <td>0.896888</td>\n      <td>208.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>max f2</td>\n      <td>0.285174</td>\n      <td>0.919860</td>\n      <td>269.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>max f0point5</td>\n      <td>0.577778</td>\n      <td>0.925011</td>\n      <td>164.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>max accuracy</td>\n      <td>0.446036</td>\n      <td>0.897211</td>\n      <td>208.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>max precision</td>\n      <td>0.999483</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>max recall</td>\n      <td>0.038624</td>\n      <td>1.000000</td>\n      <td>388.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>max specificity</td>\n      <td>0.999483</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>max absolute_mcc</td>\n      <td>0.487176</td>\n      <td>0.796188</td>\n      <td>193.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>max min_per_class_accuracy</td>\n      <td>0.433802</td>\n      <td>0.895202</td>\n      <td>212.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>max mean_per_class_accuracy</td>\n      <td>0.446036</td>\n      <td>0.897280</td>\n      <td>208.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>max tns</td>\n      <td>0.999483</td>\n      <td>3168.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>max fns</td>\n      <td>0.999483</td>\n      <td>3095.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>max fps</td>\n      <td>0.005149</td>\n      <td>3168.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>max tps</td>\n      <td>0.038624</td>\n      <td>3214.000000</td>\n      <td>388.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>max tnr</td>\n      <td>0.999483</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>max fnr</td>\n      <td>0.999483</td>\n      <td>0.962974</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>max fpr</td>\n      <td>0.005149</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>max tpr</td>\n      <td>0.038624</td>\n      <td>1.000000</td>\n      <td>388.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 50.36 %, avg score: 50.35 %\n"
     ]
    },
    {
     "data": {
      "text/plain": "    group  cumulative_data_fraction  lower_threshold      lift  \\\n0       1                  0.010028         0.999457  1.985688   \n1       2                  0.020056         0.998973  1.985688   \n2       3                  0.030085         0.998191  1.985688   \n3       4                  0.040113         0.997255  1.985688   \n4       5                  0.050141         0.996107  1.985688   \n5       6                  0.100125         0.985883  1.985688   \n6       7                  0.150110         0.963940  1.985688   \n7       8                  0.200094         0.922081  1.985688   \n8       9                  0.300063         0.778458  1.970126   \n9      10                  0.400031         0.598424  1.767822   \n10     11                  0.500000         0.437130  1.213822   \n11     12                  0.599969         0.313509  0.619360   \n12     13                  0.699937         0.223483  0.267663   \n13     14                  0.799906         0.156804  0.155618   \n14     15                  0.899875         0.096644  0.028011   \n15     16                  1.000000         0.004141  0.006215   \n\n    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n0          1.985688       1.000000  0.999740                  1.000000   \n1          1.985688       1.000000  0.999224                  1.000000   \n2          1.985688       1.000000  0.998581                  1.000000   \n3          1.985688       1.000000  0.997752                  1.000000   \n4          1.985688       1.000000  0.996770                  1.000000   \n5          1.985688       1.000000  0.991800                  1.000000   \n6          1.985688       1.000000  0.975957                  1.000000   \n7          1.985688       1.000000  0.944008                  1.000000   \n8          1.980503       0.992163  0.856165                  0.997389   \n9          1.927354       0.890282  0.693148                  0.970623   \n10         1.784692       0.611285  0.512861                  0.898778   \n11         1.590521       0.311912  0.374580                  0.800992   \n12         1.401583       0.134796  0.266303                  0.705843   \n13         1.245868       0.078370  0.188584                  0.627424   \n14         1.110574       0.014107  0.127912                  0.559290   \n15         1.000000       0.003130  0.060700                  0.503604   \n\n    cumulative_score  capture_rate  cumulative_capture_rate       gain  \\\n0           0.999740      0.019913                 0.019913  98.568762   \n1           0.999482      0.019913                 0.039826  98.568762   \n2           0.999182      0.019913                 0.059739  98.568762   \n3           0.998824      0.019913                 0.079652  98.568762   \n4           0.998414      0.019913                 0.099564  98.568762   \n5           0.995112      0.099253                 0.198818  98.568762   \n6           0.988734      0.099253                 0.298071  98.568762   \n7           0.977561      0.099253                 0.397324  98.568762   \n8           0.937117      0.196951                 0.594275  97.012580   \n9           0.876148      0.176727                 0.771002  76.782220   \n10          0.803514      0.121344                 0.892346  21.382158   \n11          0.732043      0.061917                 0.954263 -38.063976   \n12          0.665524      0.026758                 0.981021 -73.233678   \n13          0.605918      0.015557                 0.996577 -84.438185   \n14          0.552816      0.002800                 0.999378 -97.198873   \n15          0.503542      0.000622                 1.000000 -99.378502   \n\n    cumulative_gain  kolmogorov_smirnov  \n0         98.568762            0.019913  \n1         98.568762            0.039826  \n2         98.568762            0.059739  \n3         98.568762            0.079652  \n4         98.568762            0.099564  \n5         98.568762            0.198818  \n6         98.568762            0.298071  \n7         98.568762            0.397324  \n8         98.050305            0.592697  \n9         92.735367            0.747328  \n10        78.469197            0.790389  \n11        59.052074            0.713732  \n12        40.158340            0.566248  \n13        24.586825            0.396199  \n14        11.057437            0.200451  \n15         0.000000            0.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>group</th>\n      <th>cumulative_data_fraction</th>\n      <th>lower_threshold</th>\n      <th>lift</th>\n      <th>cumulative_lift</th>\n      <th>response_rate</th>\n      <th>score</th>\n      <th>cumulative_response_rate</th>\n      <th>cumulative_score</th>\n      <th>capture_rate</th>\n      <th>cumulative_capture_rate</th>\n      <th>gain</th>\n      <th>cumulative_gain</th>\n      <th>kolmogorov_smirnov</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.010028</td>\n      <td>0.999457</td>\n      <td>1.985688</td>\n      <td>1.985688</td>\n      <td>1.000000</td>\n      <td>0.999740</td>\n      <td>1.000000</td>\n      <td>0.999740</td>\n      <td>0.019913</td>\n      <td>0.019913</td>\n      <td>98.568762</td>\n      <td>98.568762</td>\n      <td>0.019913</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.020056</td>\n      <td>0.998973</td>\n      <td>1.985688</td>\n      <td>1.985688</td>\n      <td>1.000000</td>\n      <td>0.999224</td>\n      <td>1.000000</td>\n      <td>0.999482</td>\n      <td>0.019913</td>\n      <td>0.039826</td>\n      <td>98.568762</td>\n      <td>98.568762</td>\n      <td>0.039826</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0.030085</td>\n      <td>0.998191</td>\n      <td>1.985688</td>\n      <td>1.985688</td>\n      <td>1.000000</td>\n      <td>0.998581</td>\n      <td>1.000000</td>\n      <td>0.999182</td>\n      <td>0.019913</td>\n      <td>0.059739</td>\n      <td>98.568762</td>\n      <td>98.568762</td>\n      <td>0.059739</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0.040113</td>\n      <td>0.997255</td>\n      <td>1.985688</td>\n      <td>1.985688</td>\n      <td>1.000000</td>\n      <td>0.997752</td>\n      <td>1.000000</td>\n      <td>0.998824</td>\n      <td>0.019913</td>\n      <td>0.079652</td>\n      <td>98.568762</td>\n      <td>98.568762</td>\n      <td>0.079652</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.050141</td>\n      <td>0.996107</td>\n      <td>1.985688</td>\n      <td>1.985688</td>\n      <td>1.000000</td>\n      <td>0.996770</td>\n      <td>1.000000</td>\n      <td>0.998414</td>\n      <td>0.019913</td>\n      <td>0.099564</td>\n      <td>98.568762</td>\n      <td>98.568762</td>\n      <td>0.099564</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>0.100125</td>\n      <td>0.985883</td>\n      <td>1.985688</td>\n      <td>1.985688</td>\n      <td>1.000000</td>\n      <td>0.991800</td>\n      <td>1.000000</td>\n      <td>0.995112</td>\n      <td>0.099253</td>\n      <td>0.198818</td>\n      <td>98.568762</td>\n      <td>98.568762</td>\n      <td>0.198818</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>0.150110</td>\n      <td>0.963940</td>\n      <td>1.985688</td>\n      <td>1.985688</td>\n      <td>1.000000</td>\n      <td>0.975957</td>\n      <td>1.000000</td>\n      <td>0.988734</td>\n      <td>0.099253</td>\n      <td>0.298071</td>\n      <td>98.568762</td>\n      <td>98.568762</td>\n      <td>0.298071</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>0.200094</td>\n      <td>0.922081</td>\n      <td>1.985688</td>\n      <td>1.985688</td>\n      <td>1.000000</td>\n      <td>0.944008</td>\n      <td>1.000000</td>\n      <td>0.977561</td>\n      <td>0.099253</td>\n      <td>0.397324</td>\n      <td>98.568762</td>\n      <td>98.568762</td>\n      <td>0.397324</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>0.300063</td>\n      <td>0.778458</td>\n      <td>1.970126</td>\n      <td>1.980503</td>\n      <td>0.992163</td>\n      <td>0.856165</td>\n      <td>0.997389</td>\n      <td>0.937117</td>\n      <td>0.196951</td>\n      <td>0.594275</td>\n      <td>97.012580</td>\n      <td>98.050305</td>\n      <td>0.592697</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>0.400031</td>\n      <td>0.598424</td>\n      <td>1.767822</td>\n      <td>1.927354</td>\n      <td>0.890282</td>\n      <td>0.693148</td>\n      <td>0.970623</td>\n      <td>0.876148</td>\n      <td>0.176727</td>\n      <td>0.771002</td>\n      <td>76.782220</td>\n      <td>92.735367</td>\n      <td>0.747328</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>11</td>\n      <td>0.500000</td>\n      <td>0.437130</td>\n      <td>1.213822</td>\n      <td>1.784692</td>\n      <td>0.611285</td>\n      <td>0.512861</td>\n      <td>0.898778</td>\n      <td>0.803514</td>\n      <td>0.121344</td>\n      <td>0.892346</td>\n      <td>21.382158</td>\n      <td>78.469197</td>\n      <td>0.790389</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>12</td>\n      <td>0.599969</td>\n      <td>0.313509</td>\n      <td>0.619360</td>\n      <td>1.590521</td>\n      <td>0.311912</td>\n      <td>0.374580</td>\n      <td>0.800992</td>\n      <td>0.732043</td>\n      <td>0.061917</td>\n      <td>0.954263</td>\n      <td>-38.063976</td>\n      <td>59.052074</td>\n      <td>0.713732</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>13</td>\n      <td>0.699937</td>\n      <td>0.223483</td>\n      <td>0.267663</td>\n      <td>1.401583</td>\n      <td>0.134796</td>\n      <td>0.266303</td>\n      <td>0.705843</td>\n      <td>0.665524</td>\n      <td>0.026758</td>\n      <td>0.981021</td>\n      <td>-73.233678</td>\n      <td>40.158340</td>\n      <td>0.566248</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>14</td>\n      <td>0.799906</td>\n      <td>0.156804</td>\n      <td>0.155618</td>\n      <td>1.245868</td>\n      <td>0.078370</td>\n      <td>0.188584</td>\n      <td>0.627424</td>\n      <td>0.605918</td>\n      <td>0.015557</td>\n      <td>0.996577</td>\n      <td>-84.438185</td>\n      <td>24.586825</td>\n      <td>0.396199</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>15</td>\n      <td>0.899875</td>\n      <td>0.096644</td>\n      <td>0.028011</td>\n      <td>1.110574</td>\n      <td>0.014107</td>\n      <td>0.127912</td>\n      <td>0.559290</td>\n      <td>0.552816</td>\n      <td>0.002800</td>\n      <td>0.999378</td>\n      <td>-97.198873</td>\n      <td>11.057437</td>\n      <td>0.200451</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>16</td>\n      <td>1.000000</td>\n      <td>0.004141</td>\n      <td>0.006215</td>\n      <td>1.000000</td>\n      <td>0.003130</td>\n      <td>0.060700</td>\n      <td>0.503604</td>\n      <td>0.503542</td>\n      <td>0.000622</td>\n      <td>1.000000</td>\n      <td>-99.378502</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: xgboost\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.17826101103308145\n",
      "RMSE: 0.42220967662179587\n",
      "LogLoss: 0.5478112410975715\n",
      "Mean Per-Class Error: 0.27922410131665315\n",
      "AUC: 0.8114108331080995\n",
      "AUCPR: 0.8310235340556952\n",
      "Gini: 0.6228216662161989\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3364734426140785: \n"
     ]
    },
    {
     "data": {
      "text/plain": "          False   True   Error             Rate\n0  False  492.0  309.0  0.3858    (309.0/801.0)\n1   True  134.0  642.0  0.1727    (134.0/776.0)\n2  Total  626.0  951.0  0.2809   (443.0/1577.0)",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>False</th>\n      <th>True</th>\n      <th>Error</th>\n      <th>Rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>492.0</td>\n      <td>309.0</td>\n      <td>0.3858</td>\n      <td>(309.0/801.0)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>True</td>\n      <td>134.0</td>\n      <td>642.0</td>\n      <td>0.1727</td>\n      <td>(134.0/776.0)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Total</td>\n      <td>626.0</td>\n      <td>951.0</td>\n      <td>0.2809</td>\n      <td>(443.0/1577.0)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/plain": "                         metric  threshold       value    idx\n0                        max f1   0.336473    0.743486  249.0\n1                        max f2   0.019776    0.829587  395.0\n2                  max f0point5   0.692911    0.773481  119.0\n3                  max accuracy   0.557410    0.741281  164.0\n4                 max precision   0.999518    1.000000    0.0\n5                    max recall   0.002476    1.000000  399.0\n6               max specificity   0.999518    1.000000    0.0\n7              max absolute_mcc   0.687148    0.502958  121.0\n8    max min_per_class_accuracy   0.464632    0.730337  199.0\n9   max mean_per_class_accuracy   0.536727    0.740351  171.0\n10                      max tns   0.999518  801.000000    0.0\n11                      max fns   0.999518  743.000000    0.0\n12                      max fps   0.002476  801.000000  399.0\n13                      max tps   0.002476  776.000000  399.0\n14                      max tnr   0.999518    1.000000    0.0\n15                      max fnr   0.999518    0.957474    0.0\n16                      max fpr   0.002476    1.000000  399.0\n17                      max tpr   0.002476    1.000000  399.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>metric</th>\n      <th>threshold</th>\n      <th>value</th>\n      <th>idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>max f1</td>\n      <td>0.336473</td>\n      <td>0.743486</td>\n      <td>249.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>max f2</td>\n      <td>0.019776</td>\n      <td>0.829587</td>\n      <td>395.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>max f0point5</td>\n      <td>0.692911</td>\n      <td>0.773481</td>\n      <td>119.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>max accuracy</td>\n      <td>0.557410</td>\n      <td>0.741281</td>\n      <td>164.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>max precision</td>\n      <td>0.999518</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>max recall</td>\n      <td>0.002476</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>max specificity</td>\n      <td>0.999518</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>max absolute_mcc</td>\n      <td>0.687148</td>\n      <td>0.502958</td>\n      <td>121.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>max min_per_class_accuracy</td>\n      <td>0.464632</td>\n      <td>0.730337</td>\n      <td>199.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>max mean_per_class_accuracy</td>\n      <td>0.536727</td>\n      <td>0.740351</td>\n      <td>171.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>max tns</td>\n      <td>0.999518</td>\n      <td>801.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>max fns</td>\n      <td>0.999518</td>\n      <td>743.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>max fps</td>\n      <td>0.002476</td>\n      <td>801.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>max tps</td>\n      <td>0.002476</td>\n      <td>776.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>max tnr</td>\n      <td>0.999518</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>max fnr</td>\n      <td>0.999518</td>\n      <td>0.957474</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>max fpr</td>\n      <td>0.002476</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>max tpr</td>\n      <td>0.002476</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 49.21 %, avg score: 50.95 %\n"
     ]
    },
    {
     "data": {
      "text/plain": "    group  cumulative_data_fraction  lower_threshold      lift  \\\n0       1                  0.010146         0.999481  2.032216   \n1       2                  0.020292         0.999268  2.032216   \n2       3                  0.030438         0.998915  2.032216   \n3       4                  0.040583         0.998195  2.032216   \n4       5                  0.050095         0.997538  2.032216   \n5       6                  0.100190         0.988227  1.877871   \n6       7                  0.150285         0.967660  1.852147   \n7       8                  0.200380         0.922564  1.826422   \n8       9                  0.299937         0.748797  1.501510   \n9      10                  0.400127         0.584169  1.093281   \n10     11                  0.500317         0.455907  0.926073   \n11     12                  0.599873         0.338704  0.919028   \n12     13                  0.700063         0.249092  0.591658   \n13     14                  0.799620         0.173039  0.440098   \n14     15                  0.899810         0.105170  0.321553   \n15     16                  1.000000         0.001495  0.411588   \n\n    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n0          2.032216       1.000000  0.999747                  1.000000   \n1          2.032216       1.000000  0.999363                  1.000000   \n2          2.032216       1.000000  0.999097                  1.000000   \n3          2.032216       1.000000  0.998625                  1.000000   \n4          2.032216       1.000000  0.997867                  1.000000   \n5          1.955044       0.924051  0.994059                  0.962025   \n6          1.920745       0.911392  0.979062                  0.945148   \n7          1.897164       0.898734  0.949629                  0.933544   \n8          1.765837       0.738854  0.839072                  0.868922   \n9          1.597432       0.537975  0.667876                  0.786054   \n10         1.462990       0.455696  0.521992                  0.719899   \n11         1.372713       0.452229  0.395651                  0.675476   \n12         1.260931       0.291139  0.293629                  0.620471   \n13         1.158734       0.216561  0.210638                  0.570182   \n14         1.065517       0.158228  0.141334                  0.524313   \n15         1.000000       0.202532  0.063551                  0.492074   \n\n    cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n0           0.999747      0.020619                 0.020619  103.221649   \n1           0.999555      0.020619                 0.041237  103.221649   \n2           0.999402      0.020619                 0.061856  103.221649   \n3           0.999208      0.020619                 0.082474  103.221649   \n4           0.998953      0.019330                 0.101804  103.221649   \n5           0.996506      0.094072                 0.195876   87.787094   \n6           0.990691      0.092784                 0.288660   85.214668   \n7           0.980426      0.091495                 0.380155   82.642242   \n8           0.933507      0.149485                 0.529639   50.151028   \n9           0.866994      0.109536                 0.639175    9.328103   \n10          0.797906      0.092784                 0.731959   -7.392666   \n11          0.731147      0.091495                 0.823454   -8.097216   \n12          0.668531      0.059278                 0.882732  -40.834203   \n13          0.611522      0.043814                 0.926546  -55.990216   \n14          0.559168      0.032216                 0.958763  -67.844676   \n15          0.509512      0.041237                 1.000000  -58.841185   \n\n    cumulative_gain  kolmogorov_smirnov  \n0        103.221649            0.020619  \n1        103.221649            0.041237  \n2        103.221649            0.061856  \n3        103.221649            0.082474  \n4        103.221649            0.101804  \n5         95.504372            0.188386  \n6         92.074470            0.272430  \n7         89.716413            0.353937  \n8         76.583717            0.452236  \n9         59.743167            0.470636  \n10        46.298982            0.456054  \n11        37.271283            0.440183  \n12        26.093143            0.359636  \n13        15.873407            0.249892  \n14         6.551732            0.116066  \n15         0.000000            0.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>group</th>\n      <th>cumulative_data_fraction</th>\n      <th>lower_threshold</th>\n      <th>lift</th>\n      <th>cumulative_lift</th>\n      <th>response_rate</th>\n      <th>score</th>\n      <th>cumulative_response_rate</th>\n      <th>cumulative_score</th>\n      <th>capture_rate</th>\n      <th>cumulative_capture_rate</th>\n      <th>gain</th>\n      <th>cumulative_gain</th>\n      <th>kolmogorov_smirnov</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.010146</td>\n      <td>0.999481</td>\n      <td>2.032216</td>\n      <td>2.032216</td>\n      <td>1.000000</td>\n      <td>0.999747</td>\n      <td>1.000000</td>\n      <td>0.999747</td>\n      <td>0.020619</td>\n      <td>0.020619</td>\n      <td>103.221649</td>\n      <td>103.221649</td>\n      <td>0.020619</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.020292</td>\n      <td>0.999268</td>\n      <td>2.032216</td>\n      <td>2.032216</td>\n      <td>1.000000</td>\n      <td>0.999363</td>\n      <td>1.000000</td>\n      <td>0.999555</td>\n      <td>0.020619</td>\n      <td>0.041237</td>\n      <td>103.221649</td>\n      <td>103.221649</td>\n      <td>0.041237</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0.030438</td>\n      <td>0.998915</td>\n      <td>2.032216</td>\n      <td>2.032216</td>\n      <td>1.000000</td>\n      <td>0.999097</td>\n      <td>1.000000</td>\n      <td>0.999402</td>\n      <td>0.020619</td>\n      <td>0.061856</td>\n      <td>103.221649</td>\n      <td>103.221649</td>\n      <td>0.061856</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0.040583</td>\n      <td>0.998195</td>\n      <td>2.032216</td>\n      <td>2.032216</td>\n      <td>1.000000</td>\n      <td>0.998625</td>\n      <td>1.000000</td>\n      <td>0.999208</td>\n      <td>0.020619</td>\n      <td>0.082474</td>\n      <td>103.221649</td>\n      <td>103.221649</td>\n      <td>0.082474</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.050095</td>\n      <td>0.997538</td>\n      <td>2.032216</td>\n      <td>2.032216</td>\n      <td>1.000000</td>\n      <td>0.997867</td>\n      <td>1.000000</td>\n      <td>0.998953</td>\n      <td>0.019330</td>\n      <td>0.101804</td>\n      <td>103.221649</td>\n      <td>103.221649</td>\n      <td>0.101804</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>0.100190</td>\n      <td>0.988227</td>\n      <td>1.877871</td>\n      <td>1.955044</td>\n      <td>0.924051</td>\n      <td>0.994059</td>\n      <td>0.962025</td>\n      <td>0.996506</td>\n      <td>0.094072</td>\n      <td>0.195876</td>\n      <td>87.787094</td>\n      <td>95.504372</td>\n      <td>0.188386</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>0.150285</td>\n      <td>0.967660</td>\n      <td>1.852147</td>\n      <td>1.920745</td>\n      <td>0.911392</td>\n      <td>0.979062</td>\n      <td>0.945148</td>\n      <td>0.990691</td>\n      <td>0.092784</td>\n      <td>0.288660</td>\n      <td>85.214668</td>\n      <td>92.074470</td>\n      <td>0.272430</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>0.200380</td>\n      <td>0.922564</td>\n      <td>1.826422</td>\n      <td>1.897164</td>\n      <td>0.898734</td>\n      <td>0.949629</td>\n      <td>0.933544</td>\n      <td>0.980426</td>\n      <td>0.091495</td>\n      <td>0.380155</td>\n      <td>82.642242</td>\n      <td>89.716413</td>\n      <td>0.353937</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>0.299937</td>\n      <td>0.748797</td>\n      <td>1.501510</td>\n      <td>1.765837</td>\n      <td>0.738854</td>\n      <td>0.839072</td>\n      <td>0.868922</td>\n      <td>0.933507</td>\n      <td>0.149485</td>\n      <td>0.529639</td>\n      <td>50.151028</td>\n      <td>76.583717</td>\n      <td>0.452236</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>0.400127</td>\n      <td>0.584169</td>\n      <td>1.093281</td>\n      <td>1.597432</td>\n      <td>0.537975</td>\n      <td>0.667876</td>\n      <td>0.786054</td>\n      <td>0.866994</td>\n      <td>0.109536</td>\n      <td>0.639175</td>\n      <td>9.328103</td>\n      <td>59.743167</td>\n      <td>0.470636</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>11</td>\n      <td>0.500317</td>\n      <td>0.455907</td>\n      <td>0.926073</td>\n      <td>1.462990</td>\n      <td>0.455696</td>\n      <td>0.521992</td>\n      <td>0.719899</td>\n      <td>0.797906</td>\n      <td>0.092784</td>\n      <td>0.731959</td>\n      <td>-7.392666</td>\n      <td>46.298982</td>\n      <td>0.456054</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>12</td>\n      <td>0.599873</td>\n      <td>0.338704</td>\n      <td>0.919028</td>\n      <td>1.372713</td>\n      <td>0.452229</td>\n      <td>0.395651</td>\n      <td>0.675476</td>\n      <td>0.731147</td>\n      <td>0.091495</td>\n      <td>0.823454</td>\n      <td>-8.097216</td>\n      <td>37.271283</td>\n      <td>0.440183</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>13</td>\n      <td>0.700063</td>\n      <td>0.249092</td>\n      <td>0.591658</td>\n      <td>1.260931</td>\n      <td>0.291139</td>\n      <td>0.293629</td>\n      <td>0.620471</td>\n      <td>0.668531</td>\n      <td>0.059278</td>\n      <td>0.882732</td>\n      <td>-40.834203</td>\n      <td>26.093143</td>\n      <td>0.359636</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>14</td>\n      <td>0.799620</td>\n      <td>0.173039</td>\n      <td>0.440098</td>\n      <td>1.158734</td>\n      <td>0.216561</td>\n      <td>0.210638</td>\n      <td>0.570182</td>\n      <td>0.611522</td>\n      <td>0.043814</td>\n      <td>0.926546</td>\n      <td>-55.990216</td>\n      <td>15.873407</td>\n      <td>0.249892</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>15</td>\n      <td>0.899810</td>\n      <td>0.105170</td>\n      <td>0.321553</td>\n      <td>1.065517</td>\n      <td>0.158228</td>\n      <td>0.141334</td>\n      <td>0.524313</td>\n      <td>0.559168</td>\n      <td>0.032216</td>\n      <td>0.958763</td>\n      <td>-67.844676</td>\n      <td>6.551732</td>\n      <td>0.116066</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>16</td>\n      <td>1.000000</td>\n      <td>0.001495</td>\n      <td>0.411588</td>\n      <td>1.000000</td>\n      <td>0.202532</td>\n      <td>0.063551</td>\n      <td>0.492074</td>\n      <td>0.509512</td>\n      <td>0.041237</td>\n      <td>1.000000</td>\n      <td>-58.841185</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/plain": "                timestamp    duration  number_of_trees  training_rmse  \\\n0     2022-03-22 20:23:33   0.033 sec              0.0       0.500000   \n1     2022-03-22 20:23:33   0.128 sec              1.0       0.458871   \n2     2022-03-22 20:23:33   0.161 sec              2.0       0.437072   \n3     2022-03-22 20:23:33   0.197 sec              3.0       0.423267   \n4     2022-03-22 20:23:33   0.236 sec              4.0       0.414175   \n5     2022-03-22 20:23:33   0.284 sec              5.0       0.408541   \n6     2022-03-22 20:23:33   0.332 sec              6.0       0.403433   \n7     2022-03-22 20:23:33   0.382 sec              7.0       0.400397   \n8     2022-03-22 20:23:33   0.430 sec              8.0       0.397654   \n9     2022-03-22 20:23:33   0.480 sec              9.0       0.395230   \n10    2022-03-22 20:23:33   0.541 sec             10.0       0.394168   \n11    2022-03-22 20:23:33   0.647 sec             11.0       0.393548   \n12    2022-03-22 20:23:33   0.704 sec             12.0       0.392151   \n13    2022-03-22 20:23:33   0.756 sec             13.0       0.391166   \n14    2022-03-22 20:23:33   0.806 sec             14.0       0.390106   \n15    2022-03-22 20:23:33   0.858 sec             15.0       0.389183   \n16    2022-03-22 20:23:34   0.908 sec             16.0       0.388702   \n17    2022-03-22 20:23:34   0.960 sec             17.0       0.388311   \n18    2022-03-22 20:23:34   1.008 sec             18.0       0.388035   \n19    2022-03-22 20:23:34   1.057 sec             19.0       0.387787   \n\n    training_logloss  training_auc  training_pr_auc  training_lift  \\\n0           0.693147      0.500000         0.503604       1.000000   \n1           0.613126      0.816924         0.842750       1.950728   \n2           0.570702      0.824606         0.851408       1.985688   \n3           0.542367      0.831758         0.857694       1.985688   \n4           0.522453      0.835454         0.862137       1.985688   \n5           0.509155      0.838765         0.866357       1.985688   \n6           0.497334      0.843419         0.870357       1.985688   \n7           0.489632      0.845793         0.873069       1.985688   \n8           0.482720      0.848743         0.875827       1.985688   \n9           0.476712      0.851408         0.878321       1.985688   \n10          0.473575      0.852627         0.879395       1.985688   \n11          0.472123      0.853674         0.880188       1.985688   \n12          0.468892      0.855372         0.881427       1.985688   \n13          0.466501      0.856503         0.882567       1.985688   \n14          0.464192      0.857800         0.883874       1.985688   \n15          0.461790      0.859019         0.884586       1.985688   \n16          0.460903      0.859658         0.885210       1.985688   \n17          0.459819      0.859993         0.885539       1.985688   \n18          0.459215      0.860287         0.885813       1.985688   \n19          0.458667      0.860675         0.886136       1.985688   \n\n    training_classification_error  validation_rmse  validation_logloss  \\\n0                        0.496396         0.500000            0.693147   \n1                        0.271702         0.461035            0.617182   \n2                        0.266688         0.441028            0.578069   \n3                        0.261987         0.428343            0.552006   \n4                        0.241147         0.420257            0.534384   \n5                        0.254309         0.415518            0.523574   \n6                        0.244751         0.412782            0.517076   \n7                        0.240990         0.410858            0.512454   \n8                        0.243184         0.409683            0.509238   \n9                        0.243341         0.408832            0.507049   \n10                       0.240050         0.408488            0.506022   \n11                       0.239267         0.408050            0.505053   \n12                       0.232686         0.407655            0.504175   \n13                       0.231119         0.407781            0.504207   \n14                       0.230492         0.407272            0.502939   \n15                       0.235663         0.407321            0.502817   \n16                       0.237230         0.406770            0.501716   \n17                       0.237073         0.406601            0.501357   \n18                       0.233939         0.406408            0.500944   \n19                       0.233469         0.406327            0.500702   \n\n    validation_auc  validation_pr_auc  validation_lift  \\\n0         0.500000           0.492074         1.000000   \n1         0.801606           0.803710         1.874155   \n2         0.808967           0.815938         1.964476   \n3         0.815697           0.823440         1.964476   \n4         0.819917           0.827634         1.974153   \n5         0.822105           0.835380         2.032216   \n6         0.823215           0.835405         2.032216   \n7         0.825168           0.837589         2.032216   \n8         0.826579           0.839560         2.032216   \n9         0.827322           0.838909         2.032216   \n10        0.827662           0.840139         2.032216   \n11        0.828346           0.841511         2.032216   \n12        0.828688           0.841604         2.032216   \n13        0.828749           0.841830         2.032216   \n14        0.829602           0.843306         2.032216   \n15        0.829349           0.843500         2.032216   \n16        0.830428           0.844441         2.032216   \n17        0.830970           0.844956         2.032216   \n18        0.831139           0.845326         2.032216   \n19        0.831322           0.845474         2.032216   \n\n    validation_classification_error  \n0                          0.507926  \n1                          0.278377  \n2                          0.250476  \n3                          0.269499  \n4                          0.251110  \n5                          0.248573  \n6                          0.246037  \n7                          0.250476  \n8                          0.251110  \n9                          0.255549  \n10                         0.255549  \n11                         0.254914  \n12                         0.252378  \n13                         0.254280  \n14                         0.253012  \n15                         0.253012  \n16                         0.253012  \n17                         0.257451  \n18                         0.257451  \n19                         0.257451  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>timestamp</th>\n      <th>duration</th>\n      <th>number_of_trees</th>\n      <th>training_rmse</th>\n      <th>training_logloss</th>\n      <th>training_auc</th>\n      <th>training_pr_auc</th>\n      <th>training_lift</th>\n      <th>training_classification_error</th>\n      <th>validation_rmse</th>\n      <th>validation_logloss</th>\n      <th>validation_auc</th>\n      <th>validation_pr_auc</th>\n      <th>validation_lift</th>\n      <th>validation_classification_error</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>2022-03-22 20:23:33</td>\n      <td>0.033 sec</td>\n      <td>0.0</td>\n      <td>0.500000</td>\n      <td>0.693147</td>\n      <td>0.500000</td>\n      <td>0.503604</td>\n      <td>1.000000</td>\n      <td>0.496396</td>\n      <td>0.500000</td>\n      <td>0.693147</td>\n      <td>0.500000</td>\n      <td>0.492074</td>\n      <td>1.000000</td>\n      <td>0.507926</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>2022-03-22 20:23:33</td>\n      <td>0.128 sec</td>\n      <td>1.0</td>\n      <td>0.458871</td>\n      <td>0.613126</td>\n      <td>0.816924</td>\n      <td>0.842750</td>\n      <td>1.950728</td>\n      <td>0.271702</td>\n      <td>0.461035</td>\n      <td>0.617182</td>\n      <td>0.801606</td>\n      <td>0.803710</td>\n      <td>1.874155</td>\n      <td>0.278377</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>2022-03-22 20:23:33</td>\n      <td>0.161 sec</td>\n      <td>2.0</td>\n      <td>0.437072</td>\n      <td>0.570702</td>\n      <td>0.824606</td>\n      <td>0.851408</td>\n      <td>1.985688</td>\n      <td>0.266688</td>\n      <td>0.441028</td>\n      <td>0.578069</td>\n      <td>0.808967</td>\n      <td>0.815938</td>\n      <td>1.964476</td>\n      <td>0.250476</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>2022-03-22 20:23:33</td>\n      <td>0.197 sec</td>\n      <td>3.0</td>\n      <td>0.423267</td>\n      <td>0.542367</td>\n      <td>0.831758</td>\n      <td>0.857694</td>\n      <td>1.985688</td>\n      <td>0.261987</td>\n      <td>0.428343</td>\n      <td>0.552006</td>\n      <td>0.815697</td>\n      <td>0.823440</td>\n      <td>1.964476</td>\n      <td>0.269499</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>2022-03-22 20:23:33</td>\n      <td>0.236 sec</td>\n      <td>4.0</td>\n      <td>0.414175</td>\n      <td>0.522453</td>\n      <td>0.835454</td>\n      <td>0.862137</td>\n      <td>1.985688</td>\n      <td>0.241147</td>\n      <td>0.420257</td>\n      <td>0.534384</td>\n      <td>0.819917</td>\n      <td>0.827634</td>\n      <td>1.974153</td>\n      <td>0.251110</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td></td>\n      <td>2022-03-22 20:23:33</td>\n      <td>0.284 sec</td>\n      <td>5.0</td>\n      <td>0.408541</td>\n      <td>0.509155</td>\n      <td>0.838765</td>\n      <td>0.866357</td>\n      <td>1.985688</td>\n      <td>0.254309</td>\n      <td>0.415518</td>\n      <td>0.523574</td>\n      <td>0.822105</td>\n      <td>0.835380</td>\n      <td>2.032216</td>\n      <td>0.248573</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td></td>\n      <td>2022-03-22 20:23:33</td>\n      <td>0.332 sec</td>\n      <td>6.0</td>\n      <td>0.403433</td>\n      <td>0.497334</td>\n      <td>0.843419</td>\n      <td>0.870357</td>\n      <td>1.985688</td>\n      <td>0.244751</td>\n      <td>0.412782</td>\n      <td>0.517076</td>\n      <td>0.823215</td>\n      <td>0.835405</td>\n      <td>2.032216</td>\n      <td>0.246037</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td></td>\n      <td>2022-03-22 20:23:33</td>\n      <td>0.382 sec</td>\n      <td>7.0</td>\n      <td>0.400397</td>\n      <td>0.489632</td>\n      <td>0.845793</td>\n      <td>0.873069</td>\n      <td>1.985688</td>\n      <td>0.240990</td>\n      <td>0.410858</td>\n      <td>0.512454</td>\n      <td>0.825168</td>\n      <td>0.837589</td>\n      <td>2.032216</td>\n      <td>0.250476</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td></td>\n      <td>2022-03-22 20:23:33</td>\n      <td>0.430 sec</td>\n      <td>8.0</td>\n      <td>0.397654</td>\n      <td>0.482720</td>\n      <td>0.848743</td>\n      <td>0.875827</td>\n      <td>1.985688</td>\n      <td>0.243184</td>\n      <td>0.409683</td>\n      <td>0.509238</td>\n      <td>0.826579</td>\n      <td>0.839560</td>\n      <td>2.032216</td>\n      <td>0.251110</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td></td>\n      <td>2022-03-22 20:23:33</td>\n      <td>0.480 sec</td>\n      <td>9.0</td>\n      <td>0.395230</td>\n      <td>0.476712</td>\n      <td>0.851408</td>\n      <td>0.878321</td>\n      <td>1.985688</td>\n      <td>0.243341</td>\n      <td>0.408832</td>\n      <td>0.507049</td>\n      <td>0.827322</td>\n      <td>0.838909</td>\n      <td>2.032216</td>\n      <td>0.255549</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td></td>\n      <td>2022-03-22 20:23:33</td>\n      <td>0.541 sec</td>\n      <td>10.0</td>\n      <td>0.394168</td>\n      <td>0.473575</td>\n      <td>0.852627</td>\n      <td>0.879395</td>\n      <td>1.985688</td>\n      <td>0.240050</td>\n      <td>0.408488</td>\n      <td>0.506022</td>\n      <td>0.827662</td>\n      <td>0.840139</td>\n      <td>2.032216</td>\n      <td>0.255549</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td></td>\n      <td>2022-03-22 20:23:33</td>\n      <td>0.647 sec</td>\n      <td>11.0</td>\n      <td>0.393548</td>\n      <td>0.472123</td>\n      <td>0.853674</td>\n      <td>0.880188</td>\n      <td>1.985688</td>\n      <td>0.239267</td>\n      <td>0.408050</td>\n      <td>0.505053</td>\n      <td>0.828346</td>\n      <td>0.841511</td>\n      <td>2.032216</td>\n      <td>0.254914</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td></td>\n      <td>2022-03-22 20:23:33</td>\n      <td>0.704 sec</td>\n      <td>12.0</td>\n      <td>0.392151</td>\n      <td>0.468892</td>\n      <td>0.855372</td>\n      <td>0.881427</td>\n      <td>1.985688</td>\n      <td>0.232686</td>\n      <td>0.407655</td>\n      <td>0.504175</td>\n      <td>0.828688</td>\n      <td>0.841604</td>\n      <td>2.032216</td>\n      <td>0.252378</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td></td>\n      <td>2022-03-22 20:23:33</td>\n      <td>0.756 sec</td>\n      <td>13.0</td>\n      <td>0.391166</td>\n      <td>0.466501</td>\n      <td>0.856503</td>\n      <td>0.882567</td>\n      <td>1.985688</td>\n      <td>0.231119</td>\n      <td>0.407781</td>\n      <td>0.504207</td>\n      <td>0.828749</td>\n      <td>0.841830</td>\n      <td>2.032216</td>\n      <td>0.254280</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td></td>\n      <td>2022-03-22 20:23:33</td>\n      <td>0.806 sec</td>\n      <td>14.0</td>\n      <td>0.390106</td>\n      <td>0.464192</td>\n      <td>0.857800</td>\n      <td>0.883874</td>\n      <td>1.985688</td>\n      <td>0.230492</td>\n      <td>0.407272</td>\n      <td>0.502939</td>\n      <td>0.829602</td>\n      <td>0.843306</td>\n      <td>2.032216</td>\n      <td>0.253012</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td></td>\n      <td>2022-03-22 20:23:33</td>\n      <td>0.858 sec</td>\n      <td>15.0</td>\n      <td>0.389183</td>\n      <td>0.461790</td>\n      <td>0.859019</td>\n      <td>0.884586</td>\n      <td>1.985688</td>\n      <td>0.235663</td>\n      <td>0.407321</td>\n      <td>0.502817</td>\n      <td>0.829349</td>\n      <td>0.843500</td>\n      <td>2.032216</td>\n      <td>0.253012</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td></td>\n      <td>2022-03-22 20:23:34</td>\n      <td>0.908 sec</td>\n      <td>16.0</td>\n      <td>0.388702</td>\n      <td>0.460903</td>\n      <td>0.859658</td>\n      <td>0.885210</td>\n      <td>1.985688</td>\n      <td>0.237230</td>\n      <td>0.406770</td>\n      <td>0.501716</td>\n      <td>0.830428</td>\n      <td>0.844441</td>\n      <td>2.032216</td>\n      <td>0.253012</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td></td>\n      <td>2022-03-22 20:23:34</td>\n      <td>0.960 sec</td>\n      <td>17.0</td>\n      <td>0.388311</td>\n      <td>0.459819</td>\n      <td>0.859993</td>\n      <td>0.885539</td>\n      <td>1.985688</td>\n      <td>0.237073</td>\n      <td>0.406601</td>\n      <td>0.501357</td>\n      <td>0.830970</td>\n      <td>0.844956</td>\n      <td>2.032216</td>\n      <td>0.257451</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td></td>\n      <td>2022-03-22 20:23:34</td>\n      <td>1.008 sec</td>\n      <td>18.0</td>\n      <td>0.388035</td>\n      <td>0.459215</td>\n      <td>0.860287</td>\n      <td>0.885813</td>\n      <td>1.985688</td>\n      <td>0.233939</td>\n      <td>0.406408</td>\n      <td>0.500944</td>\n      <td>0.831139</td>\n      <td>0.845326</td>\n      <td>2.032216</td>\n      <td>0.257451</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td></td>\n      <td>2022-03-22 20:23:34</td>\n      <td>1.057 sec</td>\n      <td>19.0</td>\n      <td>0.387787</td>\n      <td>0.458667</td>\n      <td>0.860675</td>\n      <td>0.886136</td>\n      <td>1.985688</td>\n      <td>0.233469</td>\n      <td>0.406327</td>\n      <td>0.500702</td>\n      <td>0.831322</td>\n      <td>0.845474</td>\n      <td>2.032216</td>\n      <td>0.257451</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/plain": "                      variable  relative_importance  scaled_importance  \\\n0               runtimeMinutes          3040.630371           1.000000   \n1                     numVotes          2943.498047           0.968055   \n2                    startYear          2407.962646           0.791929   \n3                    writer.\\N           474.970215           0.156208   \n4   same_writer_director.False           269.822388           0.088739   \n5           originalTitle.<NA>           157.572235           0.051822   \n6               endYear.2017.0            28.185413           0.009270   \n7               endYear.2010.0            19.563330           0.006434   \n8             writer.nm1347153            19.013681           0.006253   \n9               endYear.2019.0            18.436451           0.006063   \n10            writer.nm0598531            18.351595           0.006035   \n11              endYear.2012.0            15.188862           0.004995   \n12          director.nm0000095            14.576425           0.004794   \n13          director.nm0442454            14.127379           0.004646   \n14              endYear.2015.0            14.063409           0.004625   \n15              endYear.2009.0            12.018179           0.003953   \n16              endYear.2018.0            10.552877           0.003471   \n17              endYear.1993.0             9.171253           0.003016   \n18          director.nm0347086             9.086985           0.002989   \n19          director.nm0080333             9.073699           0.002984   \n\n    percentage  \n0     0.314347  \n1     0.304305  \n2     0.248940  \n3     0.049103  \n4     0.027895  \n5     0.016290  \n6     0.002914  \n7     0.002022  \n8     0.001966  \n9     0.001906  \n10    0.001897  \n11    0.001570  \n12    0.001507  \n13    0.001461  \n14    0.001454  \n15    0.001242  \n16    0.001091  \n17    0.000948  \n18    0.000939  \n19    0.000938  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>variable</th>\n      <th>relative_importance</th>\n      <th>scaled_importance</th>\n      <th>percentage</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>runtimeMinutes</td>\n      <td>3040.630371</td>\n      <td>1.000000</td>\n      <td>0.314347</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>numVotes</td>\n      <td>2943.498047</td>\n      <td>0.968055</td>\n      <td>0.304305</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>startYear</td>\n      <td>2407.962646</td>\n      <td>0.791929</td>\n      <td>0.248940</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>writer.\\N</td>\n      <td>474.970215</td>\n      <td>0.156208</td>\n      <td>0.049103</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>same_writer_director.False</td>\n      <td>269.822388</td>\n      <td>0.088739</td>\n      <td>0.027895</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>originalTitle.&lt;NA&gt;</td>\n      <td>157.572235</td>\n      <td>0.051822</td>\n      <td>0.016290</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>endYear.2017.0</td>\n      <td>28.185413</td>\n      <td>0.009270</td>\n      <td>0.002914</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>endYear.2010.0</td>\n      <td>19.563330</td>\n      <td>0.006434</td>\n      <td>0.002022</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>writer.nm1347153</td>\n      <td>19.013681</td>\n      <td>0.006253</td>\n      <td>0.001966</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>endYear.2019.0</td>\n      <td>18.436451</td>\n      <td>0.006063</td>\n      <td>0.001906</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>writer.nm0598531</td>\n      <td>18.351595</td>\n      <td>0.006035</td>\n      <td>0.001897</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>endYear.2012.0</td>\n      <td>15.188862</td>\n      <td>0.004995</td>\n      <td>0.001570</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>director.nm0000095</td>\n      <td>14.576425</td>\n      <td>0.004794</td>\n      <td>0.001507</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>director.nm0442454</td>\n      <td>14.127379</td>\n      <td>0.004646</td>\n      <td>0.001461</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>endYear.2015.0</td>\n      <td>14.063409</td>\n      <td>0.004625</td>\n      <td>0.001454</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>endYear.2009.0</td>\n      <td>12.018179</td>\n      <td>0.003953</td>\n      <td>0.001242</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>endYear.2018.0</td>\n      <td>10.552877</td>\n      <td>0.003471</td>\n      <td>0.001091</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>endYear.1993.0</td>\n      <td>9.171253</td>\n      <td>0.003016</td>\n      <td>0.000948</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>director.nm0347086</td>\n      <td>9.086985</td>\n      <td>0.002989</td>\n      <td>0.000939</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>director.nm0080333</td>\n      <td>9.073699</td>\n      <td>0.002984</td>\n      <td>0.000938</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n"
     ]
    },
    {
     "data": {
      "text/plain": ""
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build and train the model:\n",
    "imdb_xgb = H2OXGBoostEstimator(seed=10,\n",
    "                               ntrees=200,\n",
    "                               max_depth=6)\n",
    "imdb_xgb.train(x=X,\n",
    "               y=y,\n",
    "               training_frame=train,\n",
    "               validation_frame=valid)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "# Eval performance:\n",
    "perf = imdb_xgb.model_performance()\n",
    "\n",
    "# Generate predictions on a test set (if necessary):\n",
    "pred = imdb_xgb.predict(valid)\n",
    "\n",
    "# Extract feature interactions:\n",
    "feature_interactions = imdb_xgb.feature_interaction()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# Make predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "valid_hf = h2o.H2OFrame(valid_df)\n",
    "test_hf = h2o.H2OFrame(test_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n",
      "xgboost prediction progress: |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/e/opt/anaconda3/lib/python3.9/site-packages/h2o/job.py:83: UserWarning: Test/Validation dataset column 'writer' has levels not trained on: [\"nm0000045\", \"nm0000189\", \"nm0000219\", \"nm0000389\", \"nm0000485\", \"nm0000905\", \"nm0001328\", \"nm0001355\", \"nm0001357\", \"nm0001640\", ...642 not listed..., \"nm8276452\", \"nm8442541\", \"nm8664327\", \"nm8733312\", \"nm9212368\", \"nm9282965\", \"nm9572719\", \"nm9648068\", \"nm9803391\", \"nm9912021\"]\n",
      "  warnings.warn(w)\n",
      "/Users/e/opt/anaconda3/lib/python3.9/site-packages/h2o/job.py:83: UserWarning: Test/Validation dataset column 'director' has levels not trained on: [\"nm0000045\", \"nm0000104\", \"nm0000578\", \"nm0000698\", \"nm0000797\", \"nm0001408\", \"nm0001471\", \"nm0001490\", \"nm0001692\", \"nm0001774\", ...470 not listed..., \"nm7920254\", \"nm7958316\", \"nm7978876\", \"nm8011325\", \"nm8381668\", \"nm8399396\", \"nm8734870\", \"nm9214307\", \"nm9290266\", \"nm9511013\"]\n",
      "  warnings.warn(w)\n",
      "/Users/e/opt/anaconda3/lib/python3.9/site-packages/h2o/job.py:83: UserWarning: Test/Validation dataset column 'originalTitle' has levels not trained on: [\"100% Coco\", \"36 Hours\", \"47 Meters Down\", \"9\", \"AVP: Alien vs. Predator\", \"Aathi\", \"Abad va yek rooz\", \"After Porn Ends 2\", \"Agnosia\", \"Akibiyori\", ...462 not listed..., \"Wolf\", \"Wszyscy jestesmy Chrystusami\", \"Wu ji\", \"Y tu mamá también\", \"Yankee Doodle Dandy\", \"Yesterday\", \"Young, Single & Angry\", \"Yuva\", \"Zhmurki\", \"Zugvögel - ... einmal nach Inari\"]\n",
      "  warnings.warn(w)\n",
      "/Users/e/opt/anaconda3/lib/python3.9/site-packages/h2o/job.py:83: UserWarning: Test/Validation dataset column 'endYear' has levels not trained on: [\"1951.0\"]\n",
      "  warnings.warn(w)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "███████████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/e/opt/anaconda3/lib/python3.9/site-packages/h2o/job.py:83: UserWarning: Test/Validation dataset column 'writer' has levels not trained on: [\"nm0000033\", \"nm0000265\", \"nm0000485\", \"nm0000532\", \"nm0000578\", \"nm0000671\", \"nm0000698\", \"nm0000713\", \"nm0001024\", \"nm0001220\", ...737 not listed..., \"nm8369212\", \"nm8472096\", \"nm8704877\", \"nm8962876\", \"nm9135703\", \"nm9413392\", \"nm9448203\", \"nm9489621\", \"nm9832450\", \"nm9868437\"]\n",
      "  warnings.warn(w)\n",
      "/Users/e/opt/anaconda3/lib/python3.9/site-packages/h2o/job.py:83: UserWarning: Test/Validation dataset column 'director' has levels not trained on: [\"nm0000059\", \"nm0000602\", \"nm0000671\", \"nm0000698\", \"nm0000797\", \"nm0001165\", \"nm0001428\", \"nm0001441\", \"nm0001554\", \"nm0001692\", ...539 not listed..., \"nm7121260\", \"nm7253772\", \"nm7263882\", \"nm7274555\", \"nm7278299\", \"nm8684196\", \"nm9135703\", \"nm9218697\", \"nm9522431\", \"nm9615170\"]\n",
      "  warnings.warn(w)\n",
      "/Users/e/opt/anaconda3/lib/python3.9/site-packages/h2o/job.py:83: UserWarning: Test/Validation dataset column 'originalTitle' has levels not trained on: [\"'Pimpernel' Smith\", \"1 - Nenokkadine\", \"12\", \"12 Feet Deep\", \"1776\", \"1920 Bitwa Warszawska\", \"4.3.2.1.\", \"A Bug's Life\", \"A Change of Seasons\", \"A League of Their Own\", ...516 not listed..., \"Yamla Pagla Deewana Phir Se...\", \"Young Billy Young\", \"Yuke yuke nidome no shojo\", \"Zatôichi no uta ga kikoeru\", \"Zhang jin hu\", \"Zhestokiy romans\", \"Zizek!\", \"Zoku Miyamoto Musashi: Ichijôji no kettô\", \"Zolushka\", \"Údolí vcel\"]\n",
      "  warnings.warn(w)\n",
      "/Users/e/opt/anaconda3/lib/python3.9/site-packages/h2o/job.py:83: UserWarning: Test/Validation dataset column 'endYear' has levels not trained on: [\"1925.0\", \"1950.0\"]\n",
      "  warnings.warn(w)\n"
     ]
    }
   ],
   "source": [
    "pred_valid = imdb_xgb.predict(valid_hf)\n",
    "pred_test = imdb_xgb.predict(test_hf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "pred_test_list = h2o.as_list(pred_test)['predict'].tolist()\n",
    "pred_test_list\n",
    "\n",
    "with open('output/prediction_test.txt', 'w') as f:\n",
    "    for item in pred_test_list:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "\n",
    "pred_valid_list = h2o.as_list(pred_valid)['predict'].tolist()\n",
    "pred_valid_list\n",
    "\n",
    "with open('output/prediction_validation.txt', 'w') as f:\n",
    "    for item in pred_valid_list:\n",
    "        f.write(\"%s\\n\" % item)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test 0.427255985267035\n"
     ]
    }
   ],
   "source": [
    "# check F/F+T\n",
    "print(f' test {pred_test_list.count(False)/(pred_test_list.count(False) + pred_test_list.count(True))}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " valid 0.48586387434554973\n"
     ]
    }
   ],
   "source": [
    "# check F/F+T\n",
    "print(f' valid {pred_test_list.count(False)/(pred_valid_list.count(False) + pred_valid_list.count(True))}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}